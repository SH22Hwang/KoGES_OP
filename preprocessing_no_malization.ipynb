{
 "cells": [
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFgAAAAtCAYAAAAqeqxGAAADNklEQVRoge2avZaiMBiGH/bMpeAUO14BXAHaUNFuhyU0dpZ2NlCablsqG+QK5AqYLdbcS7bQPQqC6+waBvbkOSeFDubnTUi+fO9YVVUpDNp4AXh7e/vsfvyXvL+/8+WzO/G/YwTWjBFYM0ZgzdwRWJK6FpabIjueKBYWlnUpi6L1KRaWS9pVSbPV1K3V2VV3s+1audPnvukWWOZkODhlRt7S22JhMWOPUupcjnzdXQ/sPEHWDPHRXoXX9SqU2sOsLpy3vfz9mDj13xwi7I+2qYlOgWWeQfCdVViS3ShcsBMOydK7+s4m2l4GJtNvxNM9Su0J/7mbHlt1JCFm0v6aDJYOgQs2MQRzG88PKbP8w6+cHR1QW+/PDz5eI9EqBLFjTBK3C1zsEE7A3AY8n7CM2dRG5bFMIJ48vrc+Bc8npOLnUDbYB2gVuNgJnGB+ft09/BDErr5u7OiA2k+JJxaWtRjVquqTW4Flylo4BPPLMeH5Ha+mt0UpxT4UzCwLV/dylj+p9LbwdG4ElnlGSXlemecyE4Bg3SGgt1WoYwLxN71bxvEH5e+tayQ0BJbkWYmTHBth0ikUunvY2a9MtXa1YDEThKvhhGCPUBdY5mRlyCq6HYI9Dy4xsUxxG+GSTNeXg/HZyBTXmlElR54amPRATeBiE1OGPq1jsCNWYUm8KcCOOPi72u1pkgUcnxXgi1n9Zjb5wUopDi0TP3SsqqqUyQfr4ZPywQWLjhzCyC5pD/HSf5MeW6XY9t/wp2DSlZoxAmvmBU6bsUEPxlXWiHGVe8AIrBkjsGaMwJoZrKt891YnU9yr/POQHeZhusqOQ7W+M7GbmPLq85Ad5mG6ytOAgPaJRaasq4Tk363qXhioq/zKPOCUGm1wmvg5r39Zc98M1lW2oxWhWDfqL9jE01ZDYKgM2FX28Bvbk0zXiC5DYKAM2lX2lgnEm3O7kjyjse8Pn2G7yvacwBHsCqDYEDMuRxluEu4XV7npf8nUZZLlyKgj7NHiKp/+XcpaLwBBuFKjcpRhDK6ytyRBIMoQf1y7AzBUV7neMPPAwUmWozrcfmNcZY0YV7kHjKusGZOu1IwRWDPGVdbML8pd86qX007BAAAAAElFTkSuQmCC"
    }
   },
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 데이터 전처리\n",
    "\n",
    "@author 컴퓨터과학과 황승현\n",
    "KoGes 데이터 전처리\n",
    "\n",
    "2023-10-04\n",
    "데이터 표준화, 정규화 하지 않기!\n",
    "X_train만 증강하기!\n",
    "\n",
    "전처리 절차\n",
    "\n",
    "1. 데이터셋 분리\n",
    "    - 여성(폐경 전) < AS1_PMYN_C: 1\n",
    "    - 여성(폐경 후) < AS1_PMYN_C: 2\n",
    "2. 각각 사용할 독립변수, 종속변수 행 추출\n",
    "3. 질환유무, 약물력 변수 가공\n",
    "4. 가족력, 가족과의 관계 변수 가공\n",
    "    - 부, 모, 형제자매, 기타 -> 부모, 형제자매, 기타, 해당없음\n",
    "5. 종속변수 AS1_OP 가공\n",
    "    - AS1_DT\n",
    "    - AS1_MT\n",
    "6. 데이터셋을 DataFrame으로 불러오고 독립변수는 4가지로 분류 (binary, cath0, cath1, cnt)\n",
    "    - 표준화 X\n",
    "    - binary: 범주형(binary) 변수\n",
    "    -  catH0: 계층 없는 범주형(>03) 변수, 벡터화(one-hot-encoding)\n",
    "    -  catH1: 계층 있는 범주형 변수\n",
    "    -    cnt: 연속형 변수, 정규화\n",
    "\n",
    "7. 결측값 대치\n",
    "    - binary, cath0, cath1: 각 칼럼의 최빈값으로 대치\n",
    "    - cnt: 평균값으로 대치\n",
    "\n",
    "-----\n",
    "8. X_train 변수 스케일링\n",
    "  - 정규화(normalization): 0, 1\n",
    "  - 표준화(standardization): 평균: 0 표준편차: 1\n",
    "  - 계층화(quantile transform): 4분위 수"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 준비\n",
    "\n",
    "- 라이브러리 불러오기\n",
    "- 데이터셋, 사용할 변수 불러오기"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-04T10:58:47.080850Z",
     "end_time": "2023-10-04T10:58:52.442850Z"
    }
   },
   "outputs": [],
   "source": [
    "# 라이브러리 불러오기\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import QuantileTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-08-18T19:39:01.077879Z",
     "end_time": "2023-08-18T19:39:02.122881Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dataset/Dataset_OP_230614_raw.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 6\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# 데이터셋 불러오기\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m# dataset = pd.read_csv(\"dataset/Dataset_OP_230316_raw.csv\", index_col=0, na_values=[77777, 99999, '#NULL!', ' ']) # 사용안함\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# dataset = pd.read_csv(\"dataset/Dataset_OP_230330_raw.csv\", index_col=0, na_values=[77777, 99999, '#NULL!', ' ']) # 사용안함\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# dataset = pd.read_csv(\"dataset/Dataset_OP_230417_raw.csv\", index_col=0, na_values=[77777, 99999, '#NULL!', ' ']) # 사용안함\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# dataset = pd.read_csv(\"dataset/Dataset_OP_230424_raw.csv\", index_col=0, na_values=[77777, 99999, '#NULL!', ' ']) # 사용안함\u001B[39;00m\n\u001B[1;32m----> 6\u001B[0m dataset \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdataset/Dataset_OP_230614_raw.csv\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex_col\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mna_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m77777\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m99999\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m#NULL!\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m \u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      7\u001B[0m dataset\u001B[38;5;241m.\u001B[39mhead\n",
      "File \u001B[1;32mC:\\GIthub\\KoGES_OP\\venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001B[0m, in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[0;32m    899\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[0;32m    900\u001B[0m     dialect,\n\u001B[0;32m    901\u001B[0m     delimiter,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    908\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[0;32m    909\u001B[0m )\n\u001B[0;32m    910\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[1;32m--> 912\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\GIthub\\KoGES_OP\\venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001B[0m, in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    574\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[0;32m    576\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[1;32m--> 577\u001B[0m parser \u001B[38;5;241m=\u001B[39m TextFileReader(filepath_or_buffer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    579\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[0;32m    580\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[1;32mC:\\GIthub\\KoGES_OP\\venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[1;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[0;32m   1404\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m   1406\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 1407\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\GIthub\\KoGES_OP\\venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[1;34m(self, f, engine)\u001B[0m\n\u001B[0;32m   1659\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[0;32m   1660\u001B[0m         mode \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m-> 1661\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1662\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1663\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1664\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1665\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcompression\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1666\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmemory_map\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1667\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1668\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding_errors\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstrict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1669\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstorage_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1670\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1671\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1672\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[1;32mC:\\GIthub\\KoGES_OP\\venv\\lib\\site-packages\\pandas\\io\\common.py:859\u001B[0m, in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    854\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m    855\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[0;32m    856\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[0;32m    857\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[0;32m    858\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[1;32m--> 859\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[0;32m    860\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    861\u001B[0m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    862\u001B[0m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    863\u001B[0m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    864\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    865\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    866\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    867\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[0;32m    868\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'dataset/Dataset_OP_230614_raw.csv'"
     ]
    }
   ],
   "source": [
    "# 데이터셋 불러오기\n",
    "# dataset = pd.read_csv(\"dataset/Dataset_OP_230316_raw.csv\", index_col=0, na_values=[77777, 99999, '#NULL!', ' ']) # 사용안함\n",
    "# dataset = pd.read_csv(\"dataset/Dataset_OP_230330_raw.csv\", index_col=0, na_values=[77777, 99999, '#NULL!', ' ']) # 사용안함\n",
    "# dataset = pd.read_csv(\"dataset/Dataset_OP_230417_raw.csv\", index_col=0, na_values=[77777, 99999, '#NULL!', ' ']) # 사용안함\n",
    "# dataset = pd.read_csv(\"dataset/Dataset_OP_230424_raw.csv\", index_col=0, na_values=[77777, 99999, '#NULL!', ' ']) # 사용안함\n",
    "dataset = pd.read_csv(\"dataset/Dataset_OP_230614_raw.csv\", index_col=0, na_values=[77777, 99999, '#NULL!', ' '])\n",
    "dataset.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-18T19:39:02.121878Z",
     "end_time": "2023-08-18T19:39:02.211878Z"
    }
   },
   "outputs": [],
   "source": [
    "# 특성별로 분류\n",
    "# var_to_use = pd.read_csv(\"dataset/var_to_use_2023-03-30T2240I.csv\")\n",
    "# var_to_use = pd.read_csv(\"dataset/var_to_use_2023-04-21T1258I.csv\")\n",
    "# var_to_use = pd.read_csv(\"dataset/var_to_use_2023-04-24T1830I.csv\")\n",
    "# var_to_use = pd.read_csv(\"dataset/var_to_use_2023-04-28T1610I.csv\")\n",
    "var_to_use = pd.read_csv(\"dataset/var_to_use_2023-06-13T1650I.csv\")\n",
    "var_to_use\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 가공\n",
    "\n",
    "- 기존 데이터로 새로운 데이터 만들기\n",
    "- if 문 쓰면 안됨!\n",
    "    - The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
    "- np.where 사용할 것!"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 종속변수 결측값 drop"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 종속변수의 결측값이 있으면 drop\n",
    "dataset.dropna(subset=['AS1_DT', 'AS1_MT'], inplace=True)\n",
    "\n",
    "# 남성(1) drop, 여성(2)만 가져옴\n",
    "dataset = dataset[dataset['AS1_SEX'] == 2]\n",
    "\n",
    "# 새로운 종속변수 만들기 OP: 골다공증 여부\n",
    "dataset['OP'] = np.where((dataset['AS1_DT'] <= -2.5) | (dataset['AS1_MT'] <= -2.5), 1, 0)\n",
    "dataset.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-18T19:39:02.153878Z",
     "end_time": "2023-08-18T19:39:02.257879Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 각종 질환 가공\n",
    "\n",
    "- 질환 유무\n",
    "    - 각종 종양 유무 (AS1_TOTCA1)\n",
    "- 약물력\n",
    "- 가족력"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-18T19:39:02.230910Z",
     "end_time": "2023-08-18T19:39:02.349879Z"
    }
   },
   "outputs": [],
   "source": [
    "# 질환유무 가공\n",
    "disease_list = np.array(['HT', 'DM', 'AL', 'MI', 'TH', # 질환 목록\n",
    "                         'CH', 'CD', 'LP', 'AS', 'CL',\n",
    "                         'KD', 'CV', 'GT' ]) # UL, PV, HN, TOTCA1 제외\n",
    "\n",
    "dataset['AS1_ARRM'] = np.where((dataset['AS1_JOAR'] == 2) | (dataset['AS1_JORM'] == 2) | (dataset['AS1_TRTAR'] == 2), 1, 0) # 관절혐은 조건 3가지 만족하면 1 아니면 0\n",
    "\n",
    "for x in disease_list:\n",
    "    dataset['AS1_'+x] = np.where((dataset['AS1_PD'+x] == 2) | (dataset['AS1_TRT'+x] == 2), 1, 0) # 질환여부 정의. AS1_PDㅇㅇ 또는 AS1_TRTㅇㅇ 이 2이면 1 아니면 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-18T19:39:02.245881Z",
     "end_time": "2023-08-18T19:39:02.401879Z"
    }
   },
   "outputs": [],
   "source": [
    "# 약물력 가공\n",
    "drug_list = np.array(['ST', 'CP', 'INS', 'HT', 'AR', \n",
    "                      'TH', 'FH', 'OS', 'STK', 'AS',\n",
    "                      'LP', 'SP', 'SL'])  # UL, DM, CP, HP 제외 SP, SL 추가\n",
    "for x in drug_list:\n",
    "    dataset['AS1_DR'+x] = np.where((dataset['AS1_DRUG'+x] == 2) | (dataset['AS1_DRUG'+x+'CU'] == 2), 1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-18T19:39:02.275879Z",
     "end_time": "2023-08-18T19:39:02.401879Z"
    }
   },
   "outputs": [],
   "source": [
    "# 와 ChatGPT가 아니었다면 np.all과 np.any를 몰랐을거야!\n",
    "# 가족력 가공\n",
    "# N: 가족력 없음, P: parent 부모, S: sibling 형제자매, O: other 기타\n",
    "# N: REL1A~4A까지 99999\n",
    "# P: REL1A~4A중 1, 2 있을 때\n",
    "# S: REL1A~4A중 3 있을 때\n",
    "# O: REL1A~4A중 4 있을 때\n",
    "\n",
    "# disease_dict = {\n",
    "#     'HT': 4, 'DM': 4, 'CVA': 3, 'HE': 2, 'OS': 2,\n",
    "#     'CVB': 2, 'CD': 2, 'PV': 2, 'LP': 2, 'GT': 2,'CH': 1\n",
    "# }\n",
    "disease_dict = { 'OS': 2 }\n",
    "\n",
    "for disease, num_family in disease_dict.items():\n",
    "    dataset[f'AS1_FM{disease}REL_N'] = np.all(dataset[[f'AS1_FM{disease}REL{i}A' for i in range(1, num_family+1)]] == 99999, axis=1).astype(int)\n",
    "    dataset[f'AS1_FM{disease}REL_P'] = np.any(dataset[[f'AS1_FM{disease}REL{i}A' for i in range(1, num_family+1)]] <= 2, axis=1).astype(int)\n",
    "    dataset[f'AS1_FM{disease}REL_S'] = np.any(dataset[[f'AS1_FM{disease}REL{i}A' for i in range(1, num_family+1)]] == 3, axis=1).astype(int)\n",
    "    dataset[f'AS1_FM{disease}REL_O'] = np.any(dataset[[f'AS1_FM{disease}REL{i}A' for i in range(1, num_family+1)]] == 4, axis=1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-18T19:39:02.291879Z",
     "end_time": "2023-08-18T19:39:02.402879Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset[[f'AS1_FM{disease}REL_{family}' for disease in disease_dict.keys() for family in ['N', 'P', 'S', 'O']]]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 여성력 가공\n",
    "\n",
    "- ~~질환~~\n",
    "- 약물\n",
    "- 기타 수술 (AS1_OBGYOP)\n",
    "    - 자궁경부암수술/ 자궁암수술/ 자궁내막암/자궁경부암,나팔관제거수술/ 만 1 나머지는 0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-18T19:39:02.306879Z",
     "end_time": "2023-08-18T19:39:02.403880Z"
    }
   },
   "outputs": [],
   "source": [
    "# 여성력 가공\n",
    "# 남성 데이터 셋을 제거하여 필요없음\n",
    "\n",
    "# 남자일 경우: 0 여자일 경우: 그대로\n",
    "# for x in ['CP', 'FH']:\n",
    "#     dataset['AS1_DR'+x] = np.where(dataset['AS1_SEX'] == '1',\n",
    "#                                    0,\n",
    "#                                    np.where((dataset['AS1_DRUG'+x] == 2) | (dataset['AS1_DRUG'+x+'CU'] == 2), 2, 1))\n",
    "\n",
    "for x in ['CP', 'FH']:\n",
    "    dataset['AS1_DR'+x] = np.where((dataset['AS1_DRUG'+x] == 2) | (dataset['AS1_DRUG'+x+'CU'] == 2), 1, 0)\n",
    "\n",
    "    \n",
    "# women = np.array(['AS1_PREG', 'AS1_HYST', 'AS1_HYSTOVARYW', 'AS1_OVARYW',\n",
    "#                   'AS1_OBGYOP', 'AS1_BRCA', 'AS1_DRCP', 'AS1_DRFH'])\n",
    "#\n",
    "# for x in women:\n",
    "#     dataset[x] = np.where((dataset['AS1_SEX'] == 1), 0, dataset[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 앉은 자세 혈압\n",
    "- AS1_BPSit1SYS\n",
    "    - AS1_BPSit1LS, AS1_BPSit1RS 변수 중 높은 값\n",
    "- AS1_BPSit1DIA\n",
    "    - AS1_BPSit1LD,  AS1_BPSit1RD  변수 중 높은 값"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset['AS1_BPSIT1SYS'] = np.where(dataset['AS1_BPSIT1LS'] > dataset['AS1_BPSIT1RS'], dataset['AS1_BPSIT1LS'], dataset['AS1_BPSIT1RS'])\n",
    "\n",
    "dataset['AS1_BPSIT1DIA'] = np.where(dataset['AS1_BPSIT1LD'] > dataset['AS1_BPSIT1RD'], dataset['AS1_BPSIT1LD'], dataset['AS1_BPSIT1RD'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-18T19:39:02.323879Z",
     "end_time": "2023-08-18T19:39:02.403880Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 타입 별 분리"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-18T19:39:02.337879Z",
     "end_time": "2023-08-18T19:39:02.403880Z"
    }
   },
   "outputs": [],
   "source": [
    "# var_to_use의 각 열 가져옴\n",
    "\n",
    "raw_binary = dataset.reindex(columns=(var_to_use['binary'].dropna()))\n",
    "raw_cath0 = dataset.reindex(columns=(var_to_use['cath0'].dropna()))\n",
    "raw_cath1 = dataset.reindex(columns=(var_to_use['cath1'].dropna()))\n",
    "raw_cnt = dataset.reindex(columns=(var_to_use['cnt'].dropna()))\n",
    "raw_label = dataset.reindex(columns=(var_to_use['dependent'].dropna()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-18T19:39:02.351879Z",
     "end_time": "2023-08-18T19:39:02.404880Z"
    }
   },
   "outputs": [],
   "source": [
    "# null인 행이 있다.... 코드북과 데이터셋이 불일치한다.\n",
    "target = raw_cnt\n",
    "null_cell = pd.Series(index=target.columns)\n",
    "null_cell = null_cell[target.isnull().sum() >= len(dataset)]  # 코드북에 없는 데이터 리스트\n",
    "null_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-18T19:39:02.367878Z",
     "end_time": "2023-08-18T19:39:02.520879Z"
    }
   },
   "outputs": [],
   "source": [
    "raw_label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결측값 대치 (문제 있음)\n",
    "- 일부 데이터의 많은 결측값\n",
    "  - 77777 -> 0\n",
    "    - AS1_TOTALC\n",
    "    - AS1_HVSMAM\n",
    "  - 99999 -> ?\n",
    "    - AS1_FMOSREL1A\n",
    "    - AS1_CA_U\n",
    "    - AS1_NA_U\n",
    "    - AS1_K_U\n",
    "\n",
    "- binary, cath0, cath1: 각 칼럼의 최빈값으로 대치\n",
    "- cnt: 평균값으로 대치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-18T19:39:02.383880Z",
     "end_time": "2023-08-18T19:39:02.536879Z"
    }
   },
   "outputs": [],
   "source": [
    "raw_binary = raw_binary.fillna(raw_binary.mode().iloc[0])\n",
    "raw_cath0 = raw_cath0.fillna(raw_cath0.mode().iloc[0])\n",
    "raw_cath1 = raw_cath1.fillna(raw_cath1.mode().iloc[0])\n",
    "raw_cnt = raw_cnt.fillna(raw_cnt.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ~~데이터 균일 분포에 매핑~~ 사용 X\n",
    "\n",
    "- 표준화 정규화 등등 사용 x\n",
    "- float로 형변환만\n",
    "\n",
    "- QuantileTransformer\n",
    "> QuantileTransformer provides a non-parametric transformation to map the data to a uniform distribution with values between 0 and 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# quantile_transformer = QuantileTransformer(random_state=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-18T19:39:02.399878Z",
     "end_time": "2023-08-18T19:39:02.554879Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-18T19:39:02.417878Z",
     "end_time": "2023-08-18T19:39:02.616878Z"
    }
   },
   "outputs": [],
   "source": [
    "# binary = pd.DataFrame(quantile_transformer.fit_transform(raw_binary), index=dataset.index, columns=raw_binary.columns).astype('float')\n",
    "# cath1 = pd.DataFrame(quantile_transformer.fit_transform(raw_cath1), index=dataset.index, columns=raw_cath1.columns).astype('float')\n",
    "# cnt = pd.DataFrame(quantile_transformer.fit_transform(raw_cnt), index=dataset.index, columns=raw_cnt.columns).astype('float')\n",
    "binary = raw_binary.astype('float')\n",
    "cath1 = raw_cath1.astype('float')\n",
    "cath0 = pd.get_dummies(raw_cath0, columns=raw_cath0.columns, drop_first=True, dtype='float64') # one-hot-encoding\n",
    "cnt = raw_cnt.astype('float')\n",
    "\n",
    "# label = pd.DataFrame(quantile_transformer.fit_transform(raw_label), index=dataset.index, columns=raw_label.columns).astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 데이터셋에 유전체 붙이기"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5217 entries, NIH2307713334 to NIH2307027315\n",
      "Columns: 140 entries, AS1_SEX to SNP_A-2242511\n",
      "dtypes: float64(127), object(13)\n",
      "memory usage: 5.6+ MB\n"
     ]
    }
   ],
   "source": [
    "diet_and_gen = pd.concat([binary, cath0, cath1, cnt, df_all_gen], axis=1)\n",
    "diet_and_gen.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4093 entries, NIH2307713334 to NIH2307534318\n",
      "Columns: 140 entries, AS1_SEX to SNP_A-2242511\n",
      "dtypes: float64(127), object(13)\n",
      "memory usage: 4.4+ MB\n"
     ]
    }
   ],
   "source": [
    "diet_and_gen.dropna().info()\n",
    "# diet_and_gen.dropna(subset=['AS1_PMYN_C'],).info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "diet_and_gen.dropna(inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-18T19:39:02.540881Z",
     "end_time": "2023-08-18T19:39:02.696878Z"
    }
   },
   "outputs": [],
   "source": [
    "X = pd.concat([binary, cath0, cath1, cnt, df_all_gen], axis=1)\n",
    "y = dataset['OP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-18T19:39:02.604878Z",
     "end_time": "2023-08-18T19:39:02.731909Z"
    }
   },
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "X.to_csv(\"dataset/scaled/X_231004.csv\")\n",
    "y.to_csv(\"dataset/scaled/y_231004.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "X, y만 파일로 내보내고, 폐경 여부는 다른 곳에서 처리"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
